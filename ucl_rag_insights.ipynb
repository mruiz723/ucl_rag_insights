{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install libraries from terminal:\n",
    "\n",
    "Open your terminal in the project's root directory and run:\n",
    "\n",
    "`pip install -r requirements.txt` \n",
    "\n",
    "This will install all the libraries listed in requirements.txt in your project's environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install libraries from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipykernel in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (6.29.5)\n",
      "Requirement already satisfied: langchain in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (0.3.18)\n",
      "Requirement already satisfied: langchain-core in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (0.3.35)\n",
      "Requirement already satisfied: langchain-openai in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (0.3.5)\n",
      "Requirement already satisfied: langchain_chroma in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (0.2.2)\n",
      "Requirement already satisfied: langchain-text-splitters in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 6)) (0.3.6)\n",
      "Requirement already satisfied: langchain-community in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 7)) (0.3.17)\n",
      "Requirement already satisfied: wikipedia in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 8)) (1.4.0)\n",
      "Requirement already satisfied: chromadb in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 11)) (0.6.3)\n",
      "Requirement already satisfied: rank_bm25 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 12)) (0.2.2)\n",
      "Requirement already satisfied: appnope in ./.venv/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 1)) (0.1.4)\n",
      "Requirement already satisfied: comm>=0.1.1 in ./.venv/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 1)) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in ./.venv/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 1)) (1.8.12)\n",
      "Requirement already satisfied: ipython>=7.23.1 in ./.venv/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 1)) (8.32.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in ./.venv/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 1)) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in ./.venv/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 1)) (5.7.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in ./.venv/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 1)) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in ./.venv/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 1)) (1.6.0)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 1)) (24.2)\n",
      "Requirement already satisfied: psutil in ./.venv/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 1)) (7.0.0)\n",
      "Requirement already satisfied: pyzmq>=24 in ./.venv/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 1)) (26.2.1)\n",
      "Requirement already satisfied: tornado>=6.1 in ./.venv/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 1)) (6.4.2)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in ./.venv/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 1)) (5.14.3)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in ./.venv/lib/python3.12/site-packages (from langchain->-r requirements.txt (line 2)) (0.3.8)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./.venv/lib/python3.12/site-packages (from langchain->-r requirements.txt (line 2)) (2.10.6)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./.venv/lib/python3.12/site-packages (from langchain->-r requirements.txt (line 2)) (2.0.38)\n",
      "Requirement already satisfied: requests<3,>=2 in ./.venv/lib/python3.12/site-packages (from langchain->-r requirements.txt (line 2)) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./.venv/lib/python3.12/site-packages (from langchain->-r requirements.txt (line 2)) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./.venv/lib/python3.12/site-packages (from langchain->-r requirements.txt (line 2)) (3.11.12)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in ./.venv/lib/python3.12/site-packages (from langchain->-r requirements.txt (line 2)) (9.0.0)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in ./.venv/lib/python3.12/site-packages (from langchain->-r requirements.txt (line 2)) (1.26.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.venv/lib/python3.12/site-packages (from langchain-core->-r requirements.txt (line 3)) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./.venv/lib/python3.12/site-packages (from langchain-core->-r requirements.txt (line 3)) (4.12.2)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.58.1 in ./.venv/lib/python3.12/site-packages (from langchain-openai->-r requirements.txt (line 4)) (1.63.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in ./.venv/lib/python3.12/site-packages (from langchain-openai->-r requirements.txt (line 4)) (0.9.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in ./.venv/lib/python3.12/site-packages (from langchain-community->-r requirements.txt (line 7)) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in ./.venv/lib/python3.12/site-packages (from langchain-community->-r requirements.txt (line 7)) (2.7.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in ./.venv/lib/python3.12/site-packages (from langchain-community->-r requirements.txt (line 7)) (0.4.0)\n",
      "Requirement already satisfied: beautifulsoup4 in ./.venv/lib/python3.12/site-packages (from wikipedia->-r requirements.txt (line 8)) (4.13.3)\n",
      "Requirement already satisfied: build>=1.0.3 in ./.venv/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 11)) (1.2.2.post1)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.6 in ./.venv/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 11)) (0.7.6)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in ./.venv/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 11)) (0.115.8)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in ./.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 11)) (0.34.0)\n",
      "Requirement already satisfied: posthog>=2.4.0 in ./.venv/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 11)) (3.13.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in ./.venv/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 11)) (1.20.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in ./.venv/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 11)) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in ./.venv/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 11)) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in ./.venv/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 11)) (0.51b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in ./.venv/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 11)) (1.30.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in ./.venv/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 11)) (0.21.0)\n",
      "Requirement already satisfied: pypika>=0.48.9 in ./.venv/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 11)) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in ./.venv/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 11)) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in ./.venv/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 11)) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in ./.venv/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 11)) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in ./.venv/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 11)) (1.70.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in ./.venv/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 11)) (4.2.1)\n",
      "Requirement already satisfied: typer>=0.9.0 in ./.venv/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 11)) (0.15.1)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in ./.venv/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 11)) (32.0.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in ./.venv/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 11)) (5.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in ./.venv/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 11)) (3.10.15)\n",
      "Requirement already satisfied: httpx>=0.27.0 in ./.venv/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 11)) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in ./.venv/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 11)) (13.9.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 2)) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 2)) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 2)) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 2)) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 2)) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 2)) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 2)) (1.18.3)\n",
      "Requirement already satisfied: pyproject_hooks in ./.venv/lib/python3.12/site-packages (from build>=1.0.3->chromadb->-r requirements.txt (line 11)) (1.2.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.venv/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->-r requirements.txt (line 7)) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./.venv/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->-r requirements.txt (line 7)) (0.9.0)\n",
      "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in ./.venv/lib/python3.12/site-packages (from fastapi>=0.95.2->chromadb->-r requirements.txt (line 11)) (0.45.3)\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb->-r requirements.txt (line 11)) (4.8.0)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb->-r requirements.txt (line 11)) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb->-r requirements.txt (line 11)) (1.0.7)\n",
      "Requirement already satisfied: idna in ./.venv/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb->-r requirements.txt (line 11)) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb->-r requirements.txt (line 11)) (0.14.0)\n",
      "Requirement already satisfied: decorator in ./.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 1)) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 1)) (0.19.2)\n",
      "Requirement already satisfied: pexpect>4.3 in ./.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 1)) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 1)) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 1)) (2.19.1)\n",
      "Requirement already satisfied: stack_data in ./.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 1)) (0.6.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core->-r requirements.txt (line 3)) (3.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from jupyter-client>=6.1.12->ipykernel->-r requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in ./.venv/lib/python3.12/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->-r requirements.txt (line 1)) (4.3.6)\n",
      "Requirement already satisfied: six>=1.9.0 in ./.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 11)) (1.17.0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in ./.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 11)) (2.38.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in ./.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 11)) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in ./.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 11)) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in ./.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 11)) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in ./.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 11)) (2.3.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in ./.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 11)) (0.9)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./.venv/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain->-r requirements.txt (line 2)) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in ./.venv/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain->-r requirements.txt (line 2)) (0.23.0)\n",
      "Requirement already satisfied: coloredlogs in ./.venv/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 11)) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in ./.venv/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 11)) (25.2.10)\n",
      "Requirement already satisfied: protobuf in ./.venv/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 11)) (5.29.3)\n",
      "Requirement already satisfied: sympy in ./.venv/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 11)) (1.13.3)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai->-r requirements.txt (line 4)) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai->-r requirements.txt (line 4)) (0.8.2)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai->-r requirements.txt (line 4)) (1.3.1)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in ./.venv/lib/python3.12/site-packages (from opentelemetry-api>=1.2.0->chromadb->-r requirements.txt (line 11)) (1.2.18)\n",
      "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in ./.venv/lib/python3.12/site-packages (from opentelemetry-api>=1.2.0->chromadb->-r requirements.txt (line 11)) (8.5.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in ./.venv/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 11)) (1.67.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.30.0 in ./.venv/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 11)) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.30.0 in ./.venv/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 11)) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.51b0 in ./.venv/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 11)) (0.51b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.51b0 in ./.venv/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 11)) (0.51b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.51b0 in ./.venv/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 11)) (0.51b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.51b0 in ./.venv/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 11)) (0.51b0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in ./.venv/lib/python3.12/site-packages (from opentelemetry-instrumentation==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 11)) (1.17.2)\n",
      "Requirement already satisfied: asgiref~=3.0 in ./.venv/lib/python3.12/site-packages (from opentelemetry-instrumentation-asgi==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 11)) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in ./.venv/lib/python3.12/site-packages (from posthog>=2.4.0->chromadb->-r requirements.txt (line 11)) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in ./.venv/lib/python3.12/site-packages (from posthog>=2.4.0->chromadb->-r requirements.txt (line 11)) (2.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain->-r requirements.txt (line 2)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in ./.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain->-r requirements.txt (line 2)) (2.27.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in ./.venv/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community->-r requirements.txt (line 7)) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain->-r requirements.txt (line 2)) (3.4.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.12/site-packages (from rich>=10.11.0->chromadb->-r requirements.txt (line 11)) (3.0.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./.venv/lib/python3.12/site-packages (from tiktoken<1,>=0.7->langchain-openai->-r requirements.txt (line 4)) (2024.11.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in ./.venv/lib/python3.12/site-packages (from tokenizers>=0.13.2->chromadb->-r requirements.txt (line 11)) (0.28.1)\n",
      "Requirement already satisfied: click>=8.0.0 in ./.venv/lib/python3.12/site-packages (from typer>=0.9.0->chromadb->-r requirements.txt (line 11)) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in ./.venv/lib/python3.12/site-packages (from typer>=0.9.0->chromadb->-r requirements.txt (line 11)) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in ./.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 11)) (0.6.4)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in ./.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 11)) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in ./.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 11)) (1.0.4)\n",
      "Requirement already satisfied: websockets>=10.4 in ./.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 11)) (14.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./.venv/lib/python3.12/site-packages (from beautifulsoup4->wikipedia->-r requirements.txt (line 8)) (2.6)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./.venv/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 11)) (5.5.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./.venv/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 11)) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./.venv/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 11)) (4.9)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb->-r requirements.txt (line 11)) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb->-r requirements.txt (line 11)) (2025.2.0)\n",
      "Requirement already satisfied: zipp>=3.20 in ./.venv/lib/python3.12/site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb->-r requirements.txt (line 11)) (3.21.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./.venv/lib/python3.12/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->-r requirements.txt (line 1)) (0.8.4)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb->-r requirements.txt (line 11)) (0.1.2)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./.venv/lib/python3.12/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./.venv/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel->-r requirements.txt (line 1)) (0.2.13)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.venv/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community->-r requirements.txt (line 7)) (1.0.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in ./.venv/lib/python3.12/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 11)) (10.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./.venv/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 1)) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./.venv/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 1)) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in ./.venv/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 1)) (0.2.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy->onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 11)) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in ./.venv/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 11)) (0.6.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add environment variables.\n",
    "\n",
    "#### Set up observability with LangSmith, the openai_api_key, and add the user_agent.\n",
    "In our configuration (.zshrc) file for Zsh (Z Shell), we add:\n",
    "```bash\n",
    "export LANGSMITH_TRACING=true\n",
    "export LANGSMITH_ENDPOINT=\"https://api.smith.langchain.com\"\n",
    "export LANGSMITH_API_KEY=\"your-api-key\"\n",
    "export LANGSMITH_PROJECT=\"ucl_rag_insights\"\n",
    "export OPENAI_USER_AGENT=\"your-user-agent\"\n",
    "export OPENAI_API_KEY=\"your-open-ai-api-key\"\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Libraries\n",
    "import os\n",
    "\n",
    "# Third Party Libraries\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display\n",
    "from langchain import hub\n",
    "from langchain_chroma import Chroma\n",
    "#from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "# My Libraries\n",
    "from helpers import to_markdown, format_docs, get_session_history, load_wikipedia_with_cache, split_text_documents, display_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the USER_AGENT environment variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> ### UserAgent:\n",
       "> ucl_rag_insights"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the USER_AGENT environment variable\n",
    "user_agent = os.getenv(\"OPENAI_USER_AGENT\")\n",
    "if user_agent:\n",
    "    display(to_markdown(f\"### UserAgent:\\n{user_agent}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize an OpenAI model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [\n",
    "    \"Liga de Campeones de la UEFA\",\n",
    "    #\"2021–22 UEFA Champions League\",\n",
    "    \"2022–23 UEFA Champions League\",  \n",
    "    \"2023–24 UEFA Champions League\",\n",
    "    #\"2024–25 UEFA Champions League\",\n",
    "]\n",
    "\n",
    "docs = []\n",
    "\n",
    "for title in titles:\n",
    "    docs.extend(load_wikipedia_with_cache(title))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = split_text_documents(\n",
    "    docs,\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store documents in Chroma vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = database.as_retriever()\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the RAG pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> #### Who have won the champions League?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "> A total of 23 clubs have won the UEFA Champions League/European Cup, with Real Madrid holding the record for the most victories at 15 times. Other notable winners include Ajax, Bayern Munich, AC Milan, Liverpool, and Barcelona. The current champions are Real Madrid, who won the 2024 final against Borussia Dortmund."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question_1 = \"Who have won the champions League?\"\n",
    "answer_1 = rag_chain.invoke(question_1)\n",
    "display_answer(question_1, answer_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup a conversational_rag_chain (Chat History)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> ##### SYSTEM_PROMPT: You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, say that you don't know. Use three sentences maximum and keep the answer concise.\n",
       "> {context}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CONTEXTUALIZE_Q_SYSTEM_PROMPT = (\n",
    "    \"Given a chat history and the latest user question \"\n",
    "    \"which might reference context in the chat history, \"\n",
    "    \"formulate a standalone question which can be understood \"\n",
    "    \"without the chat history. Do NOT answer the question, \"\n",
    "    \"just reformulate it if needed and otherwise return it as is.\"\n",
    ")\n",
    "\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", CONTEXTUALIZE_Q_SYSTEM_PROMPT),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm,\n",
    "    retriever,\n",
    "    contextualize_q_prompt\n",
    ")\n",
    "\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "display(to_markdown(f\"##### SYSTEM_PROMPT: {SYSTEM_PROMPT}\"))\n",
    "\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", SYSTEM_PROMPT),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)\n",
    "\n",
    "conversational_rag_chain = RunnableWithMessageHistory(\n",
    "    rag_chain,\n",
    "    get_session_history, # This function updates and retrieves the chat history\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    output_messages_key=\"answer\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function uses to answer questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_this(question, rag_with_memory_chain, key_question=\"input\", key_answer=\"answer\"):\n",
    "    CONFIG = {\n",
    "        \"configurable\": {\"session_id\": \"ucl-rag-insights-session\"}\n",
    "    }\n",
    "    return rag_with_memory_chain.invoke(\n",
    "        {key_question: question},\n",
    "        config=CONFIG,\n",
    "    )[key_answer]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the conversational RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> #### Store:\n",
       "> {}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "> #### What do we know about Real Madrid?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "> Real Madrid are the defending champions of the UEFA Champions League, having won their record-extending 15th title. They also earned a spot to compete in the 2024 UEFA Super Cup and the inaugural edition of the FIFA Intercontinental Cup. They have a strong performance history, winning six titles in eleven seasons."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question_2 = \"What do we know about Real Madrid?\"\n",
    "answer_2 = answer_this(question_2, conversational_rag_chain)\n",
    "display_answer(question_2, answer_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ask another question about the topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> #### Store:\n",
       "> {'ucl-rag-insights-session': InMemoryChatMessageHistory(messages=[HumanMessage(content='What do we know about Real Madrid?', additional_kwargs={}, response_metadata={}), AIMessage(content='Real Madrid are the defending champions of the UEFA Champions League, having won their record-extending 15th title in the previous season. They also earned a spot in the 2024 UEFA Super Cup and qualified for the 2025 FIFA Club World Cup. Additionally, they have a successful history in European competitions, winning multiple titles.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Did Real Madrid win its 15th title?', additional_kwargs={}, response_metadata={}), AIMessage(content='Yes, Real Madrid won their record-extending 15th title in the previous season.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Did Real Madrid earn a spot in the 2024 UEFA Super Cup?', additional_kwargs={}, response_metadata={}), AIMessage(content='Yes, Real Madrid earned a spot in the 2024 UEFA Super Cup by winning the 2023–24 UEFA Champions League.', additional_kwargs={}, response_metadata={}), HumanMessage(content='What do we know about Real Madrid?', additional_kwargs={}, response_metadata={}), AIMessage(content='Real Madrid is a highly successful football club that recently won its record-extending 15th UEFA Champions League title. They have secured their sixth title in eleven seasons and earned a place in the 2024 UEFA Super Cup, facing Atalanta, as well as a chance to compete in the inaugural FIFA Intercontinental Cup. The club has a rich history in European competitions and has qualified for the 2025 FIFA Club World Cup.', additional_kwargs={}, response_metadata={})])}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "> #### Did Real Madrid win its 15th title?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "> Yes, Real Madrid won their record-extending 15th title in the previous season."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question_3 = \"Did Real Madrid win its 15th title?\"\n",
    "answer_3 = answer_this(question_3)\n",
    "display_answer(question_3, answer_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ask another question about the topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> #### Store:\n",
       "> {'ucl-rag-insights-session': InMemoryChatMessageHistory(messages=[HumanMessage(content='What do we know about Real Madrid?', additional_kwargs={}, response_metadata={}), AIMessage(content='Real Madrid are the defending champions of the UEFA Champions League, having won their record-extending 15th title in the previous season. They also earned a spot in the 2024 UEFA Super Cup and qualified for the 2025 FIFA Club World Cup. Additionally, they have a successful history in European competitions, winning multiple titles.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Did Real Madrid win its 15th title?', additional_kwargs={}, response_metadata={}), AIMessage(content='Yes, Real Madrid won their record-extending 15th title in the previous season.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Did Real Madrid earn a spot in the 2024 UEFA Super Cup?', additional_kwargs={}, response_metadata={}), AIMessage(content='Yes, Real Madrid earned a spot in the 2024 UEFA Super Cup by winning the 2023–24 UEFA Champions League.', additional_kwargs={}, response_metadata={}), HumanMessage(content='What do we know about Real Madrid?', additional_kwargs={}, response_metadata={}), AIMessage(content='Real Madrid is a highly successful football club that recently won its record-extending 15th UEFA Champions League title. They have secured their sixth title in eleven seasons and earned a place in the 2024 UEFA Super Cup, facing Atalanta, as well as a chance to compete in the inaugural FIFA Intercontinental Cup. The club has a rich history in European competitions and has qualified for the 2025 FIFA Club World Cup.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Did Real Madrid win its 15th title?', additional_kwargs={}, response_metadata={}), AIMessage(content='Yes, Real Madrid won their record-extending 15th title in the previous season.', additional_kwargs={}, response_metadata={})])}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "> #### Did Real Madrid earn a spot in the 2024 UEFA Super Cup?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "> Yes, Real Madrid earned a spot in the 2024 UEFA Super Cup by winning their recent UEFA Champions League title."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question_4 = \"Did Real Madrid earn a spot in the 2024 UEFA Super Cup?\"\n",
    "answer_4 = answer_this(question_4)\n",
    "display_answer(question_4, answer_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enhancements Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 🚀 Goal:\n",
    "Improve semantic retrieval by combining BM25 + Embeddings and applying Contextual Compression before passing docs to the LLM.\n",
    "\n",
    "#### 🛠 Steps We’ll Take:\n",
    "1️⃣ Hybrid Search → Combine BM25 (keyword-based) + Vector Search (semantic-based. OpenAIEmbeddings + Chroma)<br>\n",
    "2️⃣ Contextual Compression → Use an LLM to filter irrelevant content<br>\n",
    "3️⃣ LLMChainExtractor → Extract only key facts from retrieved docs\n",
    "\n",
    "\n",
    "#### 📝 What This Code Does:\n",
    "✔ Hybrid Search (BM25 + Vector) → Retrieves keyword + semantic matches<br>\n",
    "✔ Contextual Compression (LLMChainExtractor) → Filters out irrelevant content<br>\n",
    "✔ RetrievalQA (GPT-4) → Uses only meaningful retrieved text<br>\n",
    "\n",
    "🚀 Result? More accurate & cost-efficient RAG system! 🔥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_splits = split_text_documents(\n",
    "    docs,\n",
    "    chunk_size=400, # Balanced size for all three techniques\n",
    "    chunk_overlap=50 # Enough to maintain context without redundancy\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store documents in Chroma vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_database = Chroma.from_documents(documents=enhanced_splits, embedding=OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_retriever = enhanced_database.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create BM25 Retriever (Keyword Matching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_retriever = BM25Retriever.from_documents(enhanced_splits)\n",
    "bm25_retriever.k = 3  # Limit top 3 keyword-based results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine BM25 + Embeddings using an Ensemble Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, enhanced_retriever],\n",
    "    weights=[0.3, 0.7] # The second component has more influence (70%) than the first (30%). \n",
    "    # Documents are heavily unstructured and we want to prioritize semantic meaning.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Contextual Compression with LLMChainExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressor = LLMChainExtractor.from_llm(llm)\n",
    "compressed_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=hybrid_retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_rag_chain = (\n",
    "    {\"context\": compressed_retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the RetrievalQA Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_history_aware_retriever = create_history_aware_retriever(\n",
    "    llm,\n",
    "    compressed_retriever,\n",
    "    contextualize_q_prompt\n",
    ")\n",
    "\n",
    "enhanced_rag_chain = create_retrieval_chain(enhanced_history_aware_retriever, question_answer_chain)\n",
    "\n",
    "# chain_type=\"map_reduce\". Process documents individually, then combine results. Avoid the issue of exceeding token limits for large documents.\n",
    "# Default value is: chain_type=\"stuff\",  # Stuffing all retrieved docs into the LLM\n",
    "# Other options: \"refine\", \"map_rerank\"\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"map_reduce\",  \n",
    "    retriever=compressed_retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before enhancements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> #### Before enhancement"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "> #### What do we know about Real Madrid?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "> Real Madrid are the defending champions of the UEFA Champions League, having won their record-extending 15th title. They also earned a spot to compete in the 2024 UEFA Super Cup and the inaugural edition of the FIFA Intercontinental Cup. They have a strong performance history, winning six titles in eleven seasons."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# question_2 = \"What do we know about Real Madrid?\"\n",
    "\n",
    "# Before enhancement\n",
    "display(to_markdown(f\"#### Before enhancement\"))\n",
    "display_answer(question_2, answer_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After enhancement using enhanced_rag_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> #### Store:\n",
       "> {'ucl-rag-insights-session': InMemoryChatMessageHistory(messages=[HumanMessage(content='What do we know about Real Madrid?', additional_kwargs={}, response_metadata={}), AIMessage(content='Real Madrid are the defending champions of the UEFA Champions League, having won their record-extending 15th title. They also earned a spot to compete in the 2024 UEFA Super Cup and the inaugural edition of the FIFA Intercontinental Cup. They have a strong performance history, winning six titles in eleven seasons.', additional_kwargs={}, response_metadata={})])}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "> #### After enhancement using enhanced_rag_chain"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "> #### What do we know about Real Madrid?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "> Real Madrid are a highly successful football club, known for winning a record-extending 15 UEFA Champions League titles. They are the only team whose players have won all available awards in the same season, achieving this in the 2009–10 and 2017–18 seasons. The club is recognized for its competitive history and significant achievements in European football."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the conversational RAG chain with history\n",
    "enhanced_1_conversational_rag_chain = RunnableWithMessageHistory(\n",
    "    enhanced_rag_chain,  \n",
    "    get_session_history,  # Updates and retrieves chat history\n",
    "    input_messages_key=\"input\",  \n",
    "    history_messages_key=\"chat_history\", \n",
    "    output_messages_key=\"answer\" \n",
    ")\n",
    "\n",
    "answer_after_enhancement_1 = answer_this(question_2, enhanced_1_conversational_rag_chain)\n",
    "display(to_markdown(f\"#### After enhancement using enhanced_rag_chain\"))\n",
    "display_answer(question_2, answer_after_enhancement_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After enhancement using qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> #### After enhancement using qa_chain"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "> #### What do we know about Real Madrid?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "> Real Madrid are the defending champions, having won their record-extending 15th title the previous season."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the conversational RAG chain with history\n",
    "enhanced_2_conversational_rag_chain = RunnableWithMessageHistory(\n",
    "    qa_chain,  # Function that handles retrieval and QA\n",
    "    get_session_history,  # Updates and retrieves chat history\n",
    "    input_messages_key=\"query\",  # Key for input (query)\n",
    "    history_messages_key=\"chat_history\",  # Key for chat history\n",
    "    output_messages_key=\"result\"  # Key for the final answer\n",
    ")\n",
    "\n",
    "answer_after_enhancement_2 = answer_this(question_2, enhanced_conversational_rag_chain, key_question=\"query\", key_answer=\"result\")\n",
    "display(to_markdown(f\"#### After enhancement using qa_chain\"))\n",
    "display_answer(question_2, answer_after_enhancement_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop jupyter if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop jupyter lab in a specific port\n",
    "#!jupyter lab stop 8891\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
